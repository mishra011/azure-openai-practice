import os  
import requests  # To send HTTP requests
import base64  # To encode the image in Base64 format
from azure.identity import ClientSecretCredential  # To authenticate using Azure client credentials
  
# Configuration - Set up necessary values for authentication and request
TENANT_ID = "YOUR_TENANT_ID"  # Your Azure Active Directory Tenant ID
CLIENT_ID = "YOUR_CLIENT_ID"  # Your Azure App Registration Client ID
CLIENT_SECRET = "YOUR_CLIENT_SECRET"  # Your Azure App Registration Client Secret
RESOURCE = "https://management.azure.com/.default"  # The resource URL to obtain the token for
IMAGE_PATH = "YOUR_IMAGE_PATH"  # Path to the image to be uploaded and analyzed
  
# Authenticate and get token
# Create a credential object using tenant ID, client ID, and client secret
credential = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)  
# Get the authentication token to be used for subsequent requests
token = credential.get_token(RESOURCE).token  
  
# Encode the image in Base64 format
encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')  
  
# Define headers for the HTTP request
headers = {  
    "Content-Type": "application/json",  # Set the content type as JSON
    "Authorization": f"Bearer {token}"  # Bearer token for authentication
}  
  
# Payload for the request - defines the message structure for the AI interaction
payload = {
  "messages": [
    {
      "role": "system",  # The system message helps set up behavior or context for the AI
      "content": [
        {
          "type": "text",
          "text": "You are an AI assistant that helps people find information."
        }
      ]
    },
    {
      "role": "user",  # The user message that contains the image and the question
      "content": [
        {
          "type": "text",
          "text": "\n"
        },
        {
          "type": "image_url",  # Include the image as Base64-encoded data
          "image_url": {
            "url": f"data:image/jpeg;base64,{encoded_image}"
          }
        },
        {
          "type": "text",
          "text": "Give me the summary of the image and ensure to preserve the meaning."
        }
      ]
    },
    {
      "role": "assistant",  # The assistant's response to the user query
      "content": [
        {
          "type": "text",
          "text": "The image outlines the features of a vehicle across different trim levels: Smart, Pure+, Creative, and Pure+ S. ..."  # Example of a response summarizing the image content
        }
      ]
    }
  ],
  "temperature": 0.7,  # Controls the randomness of the response. Higher values make the output more diverse
  "top_p": 0.95,  # Controls the diversity of possible tokens in the response
  "max_tokens": 800  # Limits the length of the response generated by the model
}  

# Define the endpoint URL for Azure OpenAI
ENDPOINT = "https://openaixxxxxx.openai.azure.com/openai/deployments/xxxxxxxx/chat/completions?api-version=2024-02-15-xxxxxx"  
  
# Send request to the endpoint and get the response
try:  
    # Make a POST request to the Azure OpenAI endpoint with the headers and payload
    response = requests.post(ENDPOINT, headers=headers, json=payload)  
    response.raise_for_status()  # Raise an HTTPError if the response contains an error status code
except requests.RequestException as e:  # Catch any request-related errors
    raise SystemExit(f"Failed to make the request. Error: {e}")  
  
# Handle the response as needed (e.g., print or process)
# Print the JSON response from the AI model
print(response.json())